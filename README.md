# Haskell parsing benchmarks

A simple benchmark comparing the performance of different parser
implementations. The objective is to parse the following grammar:

```bnf
SUM   = SUM '+' PROD
      | SUM '-' PROD
      | PROD

PROD  = PROD '*' number
      | PROD '/' number
      | number
```

There are four parsers implemented right now:
- __Handwritten__: The parser is implemented using a CPS monad (called
  `Lexer`), managing the remaining input, the next token, the source
  position, and the failure state. Even though the source position is
  not used in this example, it is still computed because it's a very
  common requirement for a parser. Only ByteString is supported.

- __Attoparsec__: A parser using the parser combinator library _Attoparsec_. ByteString and Text are supported.

- __Megaparsec__: A paarser using the parser combinator library _Megaparsec_. ByteString and Text are supported.

- __Alex/Happy__: An LALR(1) parser, automatically generated by
  _Happy_, and a lexer, automatically generated by _Alex_. Only ByteString is supported.

## Benchmark

Parse the file generated by `gen-example.py`. It is roughly 5MB in
size and contains around 1 million numbers, each having 1 to 4 digits,
seperated by a randomly chosen operator (`+`, `-`, `*`, `/`).

Reading the file is part of the benchmark, since I would consider this
part of the parser.

## Results

| Parser                  | Time      | Factor |
|:----------------------- | ---------:| ------:|
| Handwritten             | 198  ms   | 1.00x  |
| Attoparsec (ByteString) | 280  ms   | 1.41x  |
| Attoparsec (Text)       | 355  ms   | 1.79x  |
| Megaparsec (ByteString) | 410  ms   | 2.07x  |
| Megaparsec (Text)       | 568  ms   | 2.86x  |
| Alex/Happy              | 1.01  s   | 5.07x  |

The benchmark was compiled with GHC 9.2.1, without a threaded runtime
or the LLVM code generator, but with `-O2`.

## Observations

_Attoparsec_ and _Megaparsec_ benefit greatly from the `Strict` GHC
extension, as they run twice as fast. The handwritten parser performs
best with `StrictData`. All implementations suffer from at least a 2x
slowdown when compiled with `-threaded` and run with `+RTS -N`.

## Running it yourself
```sh
$ python ./gen-example.py
$ cabal bench
```
If you want experiment with the different implementations, run

```sh
$ cabal bench --benchmark-options="--csv baseline.csv"
```

once, then make the changes you want to make, and then run

```sh
$ cabal bench --benchmark-options="--baseline baseline.csv"
```

to see how much the performance has changed.
