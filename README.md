# Haskell parsing benchmarks

A simple benchmark comparing the performance of different parser
implementations. The objective is to parse the following grammar:

```bnf
SUM   = SUM '+' PROD
      | SUM '-' PROD
      | PROD

PROD  = PROD '*' ATOM
      | PROD '/' ATOM
      | ATOM

ATOM  = integer
      | '(' SUM ')'
```

There are five parsers implemented right now:
- __Handwritten__: A handwritten lexer and recursive ascent parser. Even though
  the source position is not used in this example, it is still
  computed because it's a very common requirement for a parser. Only
  ByteString is supported.

- __Attoparsec__: A parser using the parser combinator library
  [_Attoparsec_](https://hackage.haskell.org/package/attoparsec). ByteString
  and Text are supported.

- __Megaparsec__: A parser using the parser combinator library
  [_Megaparsec_](https://hackage.haskell.org/package/megaparsec). ByteString
  and Text are supported.

- __Flatparse__: A parser using the comparatively new parser
  combinator library
  [_Flatparse_](https://hackage.haskell.org/package/flatparse). Only
  ByteString is supported.

- __Alex/Happy__: An LALR(1) parser, automatically generated by
  _Happy_, and a lexer, automatically generated by _Alex_. Only ByteString is supported.

## Benchmark

Parse the file generated by `gen-example.py`. It is roughly 5MB in
size and contains around 1 million numbers, each having 1 to 4 digits,
separated by a randomly chosen operator (`+`, `-`, `*`,
`/`). Parenthesis are randomly inserted.

Reading the file is part of the benchmark, since I would consider this
part of the parser.

## Results

| Parser                  | Time      | Factor | Memory allocated |
|:----------------------- | ---------:| ------:| ----------------:|
| Flatparse               | 206  ms   | 1.00x  | 78 MB            |
| Handwritten             | 221  ms   | 1.07x  | 292 MB           |
| Attoparsec (ByteString) | 366  ms   | 1.78x  | 1.3 GB           |
| Attoparsec (Text)       | 461  ms   | 2.24x  | 1.2 GB           |
| Megaparsec (ByteString) | 541  ms   | 2.63x  | 2.3 GB           |
| Megaparsec (Text)       | 760  ms   | 3.69x  | 3.0 GB           |
| Alex/Happy              | 1.13  s   | 5.48x  | 2.4 GB           |

_Note: Memory allocated is not peak memory consumption, since it does
not decrease, when memory is freed._

The benchmark was compiled with GHC 9.2.1, without a threaded runtime
or the LLVM code generator, but with `-O2`.

## Notes

_Flatparse_, _Attoparsec_, and _Megaparsec_ benefit greatly from the
`Strict` GHC extension, as they run twice as fast. The handwritten
parser performs best with `StrictData`. All implementations suffer
from at least a 2x slowdown when compiled with `-threaded` and run
with `+RTS -N`.

I did try benchmarking
[Earley](https://hackage.haskell.org/package/Earley), but on a file
this size it consumed multiple gigabytes of memory. On smaller files
it was around 200x slower than _Flatparse_. I did however not use a
tokenizer, which could have improved its performance.

## Running it yourself
```sh
$ python ./gen-example.py
$ cabal bench
```
If you want experiment with the different implementations, run

```sh
$ cabal bench --benchmark-options="--csv baseline.csv +RTS -T"
```

once, then make the changes you want to make, and then run

```sh
$ cabal bench --benchmark-options="--baseline baseline.csv +RTS -T"
```

to see how much the performance has changed.
