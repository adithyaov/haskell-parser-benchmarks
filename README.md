# Haskell parsing benchmarks

A simple benchmark comparing the performance of different parser
implementations. The objective is to parse the following grammar:

```bnf
SUM   = SUM '+' PROD
      | SUM '-' PROD
      | PROD

PROD  = PROD '*' number
      | PROD '/' number
      | number
```

There are three parsers implemented right now:
- __Handwritten__: The parser is implemented using a CPS monad (called
  `Lexer`), managing the remaining input, the next token, the source
  position, and the failure state. Even though the source position is
  not used in this example, it is still computed because it's a very
  common requirement for a parser.

- __Attoparsec__: Your typical parser using parser-combinators. Pretty
  similar to the handwritten parser, except that we backtrack when
  an unexpected token is encountered, unlike above, where we decide
  whether to shift or reduce, based on the next token.

- __Megaparsec__: Same as above, but using Text instead of
  ByteString.

- __Alex/Happy__: An LALR(1) parser, automatically generated by
  _Happy_, and a lexer, automatically generated by _Alex_.

## Benchmark

Parse the file generated by `gen-example.py`. It is roughly 5MB in
size and contains around 1 million numbers, each having 1 to 4 digits,
seperated by a randomly chosen operator (`+`, `-`, `*`, `/`).

Reading the file is part of the benchmark, since I would consider this
part of the parser.

## Results

| Parser      | Time      | Factor |
|:----------- | ---------:|:------ |
| Handwritten | 208  ms   | 1.00x  |
| Attoparsec  | 296  ms   | 1.42x  |
| Megaparsec  | 589  ms   | 2.83x  |
| Alex/Happy  | 1.03  s   | 4.95x  |

The benchmark was compiled with GHC 9.2.1, without a threaded runtime
or the LLVM code generator, but with `-O2`.

## Observations

_Attoparsec_ and _Megaparsec_ benefit greatly from the `Strict`
GHC extension, as they run twice as fast. The handwritten parser
performs best with `StrictData`. All implementations suffer from atleast a
2x slowdown when compiled with `-threaded` and run with `+RTS
-N`.

## Running it yourself
```sh
$ python ./gen-example.py
$ cabal bench
```
If you want experiment with the different implementations, run

```sh
$ cabal bench --benchmark-options="--csv baseline.csv"
```

once, then make the changes you want to make, and then run

```sh
$ cabal bench --benchmark-options="--baseline baseline.csv"
```

to see how much the performance has changed.
